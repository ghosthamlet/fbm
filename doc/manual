

                 SOFTWARE FOR FLEXIBLE BAYESIAN MODELS

            BASED ON NEURAL NETWORKS AND GAUSSIAN PROCESSES

               IMPLEMENTED USING MARKOV CHAIN MONTE CARLO

            Copyright (c) 1995, 1996, 1997 by Radford M. Neal 

                        Version of 1997-01-18

Permission is granted for anyone to copy, use, or modify these
programs and accompanying documents for purposes of research or
education, provided this copyright notice is retained, and note is
made of any changes that have been made.

These programs and documents are distributed without any warranty,
express or implied.  As the programs were written for research
purposes only, they have not been tested to the degree that would be
advisable in any important application.  All use of these programs is
entirely at the user's own risk.

If you have comments, bug reports, or questions, or if you wish
permission to use these programs for commercial or any other purposes
except research or education, you may contact me at the following
address:
                   Radford Neal
                   Dept. of Statistics
                   University of Toronto
                   100 St. George Street
                   Toronto, Ontario  M5S 3G3
                   CANADA

or e-mail me at radford@stat.toronto.edu or radford@cs.toronto.edu.

Information on any updates or other related work may from time to time
be available via the World Wide Web, starting from my home page at URL
http://www.cs.toronto.edu/~radford/.


FACILITIES PROVIDED BY THIS SOFTWARE

This software implements flexible Bayesian models for regression and
classification applications that are based on multilayer perceptron
neural networks or on Gaussian processes.  The implementation uses
Markov chain Monte Carlo methods.  Software modules that support
Markov chain sampling are included in the distribution, and may be
useful in other applications.  Note that I am distributing this
software to facilitate research in this area.  Potential users should
make note of the copyright notice at the beginning of this document
(or accessible via the first hypertext link).  You must obtain
permission from me before using this software for purposes other than
research or education.  You should also note that the software may
have bugs, particularly regarding recently added experimental features.

The neural network models are described in my thesis, "Bayesian
Learning for Neural Networks", which has now been published by
Springer-Verlag (ISBN 0-387-94724-8).  The neural network models
implemented are essentially as described in the Appendix of this book.
The Gaussian process models are in many ways analogous to the network
models.  The Gaussian process models implemented in this software, and
computatonal methods that used, are described in my technical report
entitled "Monte Carlo implementation of Gaussian process models for
Bayesian regression and classification", available in compressed
Postscript at URL http://www.cs.utoronto.ca/~radford/mc-gp.ps.Z.  The
Gaussian process models for regression are similar to those evaluated
by Carl Rasmussen in his thesis, "Evaluation of Gaussian Processes and
other Methods for Non-Linear Regression", available from his home
page, at the URL http://www.cs.utoronto.ca/~carl/; he also talks about
neural network models.  To understand how to use this software, it is
essential for you to have read at least one of these references.

The neural network software supports Bayesian learning for regression
problems, classification problems, and survival analysis (experimental), 
using models based on networks with any number of hidden layers, with
a wide variety of prior distributions for network parameters and
hyperparameters.  The Gaussian process software supports regression
and classification models that are similar to neural network models
with an infinite number of hidden units, using Gaussian priors.

The advantages of Bayesian learning for both types of model include
the automatic determination of "regularization" hyperparameters,
without the need for a validation set, the avoidance of overfitting
when using large networks, and the quantification of uncertainty in
predictions.  The software implements the Automatic Relevance
Determination (ARD) approach to handling inputs that may turn out to
be irrelevant (developed with David MacKay).  

For problems and networks of moderate size (eg, 200 training cases, 10
inputs, 20 hidden units), fully training a neural network model (to
the point where one can be reasonably sure that the correct Bayesian
answer has been found) typically takes several hours to a day on our
SGI machine.  However, quite good results, competitive with other
methods, are often obtained after training for under an hour. The time
required to train the Gaussian process models depends a lot on the
number of training cases.  For 100 cases, these models may take only a
few minutes to train (again, to the point where one can be reasonably
sure that convergence to the correct answer has occurred).  For 1000
cases, however, training might well require a day of computation.

The software consists of a number of programs and modules.  Four major
components are included in this distribution, each with its own
directory:
  
    util    Modules and programs of general utility.

    mc      Modules and programs that support sampling using Markov 
            chain Monte Carlo methods, using modules from util.

    net     Modules and programs that implement Bayesian inference
            for models based on multilayer perceptrons, using the
            modules from util and mc.

    gp      Modules and programs that implement Bayesian inference
            for models based on Gaussian processes, using the modules
            from util and mc.

In addition, the 'bvg' directory contains modules and programs for
sampling from a bivariate Gaussian distribution, as a simple
demonstration of the capabilities of the Markov chain Monte Carlo
facilities.  Other than by providing this example, and the detailed
documentation on various commands, I have not attempted to document
how you might go about using the Markov chain Monte Carlo modules for
another application.

The 'examples' directory contains the data sets that are used in the
tutorial examples, along with shell scripts containing the commands
used.

It is possible to use this software to do learning and prediction
without any knowledge of how the programs are written (assuming that
the software can be installed as described below without any
problems).  However, the complete source code is included so that
researchers can modify the programs to try out their own ideas.

The software is written in ANSI C, and is meant to be run in a UNIX
environment.  Specifically, it was developed on an SGI machine running
IRIX Release 5.3.  It also seems to run OK on a SPARC machine running
SunOS 5, using the 'gcc' C compiler.  As far as I know, the software
does not depend on any peculiarities of these environments (except
perhaps for the use of the drand48 psuedo-random number generator),
but you may nevertheless have problems getting it to work in
substantially different environments, and I can offer little or no
assistance in this regard.  There is no dependence on any particular
graphics package or graphical user interface.  (The 'xxx-plt' programs
are designed to allow their output to be piped directly into the
'xgraph' plotting program, but other plotting programs can be used
instead, or the numbers can be examined directly.)


INSTALLING THE SOFTWARE

The software is distributed as a Unix tar archive.  To obtain the
files, create an empty directory and change to it, download the tar
archive for the desired version by anonymous ftp or via your Web
browser to a file of the form 'fbm.YYYY-MM-DD.tar', and then issue the
Unix command

    tar xf fbm.YYYY-MM-DD.tar

If you got the archive in compressed form, as 'fbm.YYYY-MM-DD.tar.Z',
you must use the command "uncompress fbm.YYYY-MM-DD.tar.Z" before
doing the above.  The following instructions cover what to do next for
the current version; you should read the old documentation if for some
reason you are installing an older version.

The tar command should create sub-directories 'util', 'mc', 'net',
'gp', 'bvg', 'examples', 'doc', and 'bin', and place a large number of
files in these sub-directories.  It should also place the files
'README' and 'make.include' in the current directory.  If all this 
seems to have worked, you can remove the file 'fbm.YYYY-MM-DD.tar'.

The directory 'doc' contains links to all the documentation files.
The file 'manual' contains all the introductory documentation
(including this) as a simple text file; the same information is also
contained in several .doc files.  Other .doc files contain more
detailed information.  Files of the form release.YYYY-MM-DD.doc
contain information on current and past releases.  These may be of
interest if you are upgrading from an older version of the software.
You can read these text files directly, or if you have a Web browser,
you can access them via 'index.html', as described in Guide.doc.

You will probably be able to compile the programs as described below
without making having to change anything.  However, it is possible
that you will want to use a different C compiler, or set certain
compilation options.  This can probably be done by modifying the
'make.include' file in the main directory, which is included at the
beginning of all Makefiles, though for some problems you might have to
modify the 'Makefile' and 'xxx.make' files in the various directories.

The 'util' directory contains a file of 100,000 natural random bytes,
which are used in combination with pseudo-random numbers.  This file
is accessed by many of the programs, using a path name that by default
points into this 'util' directory.  If you plan on moving this file
elsewhere, you will need to change the compilation command for rand.c
at the end of 'util/util.make'.

Once you have made any required changes, you can compile the programs
by issuing the following commands

    cd util
    make
    cd ..

    cd mc
    make
    cd ..

    cd net
    make
    cd ..

    cd gp
    make
    cd ..

    cd bvg
    make
    cd ..

The last three commands can be omitted if you have no interest in the
demonstration of sampling from a bivariate Gaussian distribution. Note
that common modules will be compiled over again for each directory
where they are used; this is intentional.

It is possible that these compilation commands will fail for some
reason, in which case you'll have to figure out what's wrong and fix
it.  Note that for the makes to work correctly, the programs MUST be
kept in separate 'util', 'mc', 'net', 'gp', and 'bvg' sub-directories,
with these names.

Once the above make commands have been successful, you should put the
'bin' directory (within the main directory for this software) in your
search path.  How this is done depends on the shell program you are
using; consult a local expert if you don't know how.  This directory
contains symbolic links to all the programs making up this software
(except some that are used only for testing).  Subsequent instructions
assume that you have this 'bin' directory in your search path.


OVERVIEW OF THE SOFTWARE

This software is being distributed primarily to further research in
Bayesian learning for models based on neural networks and Gaussian
processes.  The software is designed for potentially wider use,
however.  In particular, the programs and modules in the 'util'
directory are of general utility, and those in the 'mc' directory
provide generic support for Markov chain Monte Carlo methods.  These
facilities are specialized to neural network learning by the modules
and programs in the 'net' directory, and to Gaussian process models by
the modules and programs in the 'gp' directory.  The 'bvg' directory
demonstrates in a simple context how the generic facilities in 'util'
and 'mc' can be specialized for other tasks, but users interested only
in neural networks or Gaussian processes need not concern themselves
with this.  This section provides an overview of the facilities
offered by these various components of the software.


Log files

All the programs make use of a "log file" facility supported by
modules and programs in 'util'.  A log file records all the
information pertaining to a "run" of an iterative program.  The first
few records of the log file (with "indexes" of -1) contain the
specifications for the run (such as the network architecture and the
source of training data).  These records are written by "spec"
programs (eg, 'net-spec' and 'data-spec') that the user invokes at the
beginning of the run.  Once the run has been specified, the program
that performs iterations is invoked (eg, 'net-mc').  This program will
append further records to the log file, one for each iteration for
which the user has asked the state to be saved, which will usually be
every iteration, unless minimizing disk usage is a concern.  Each
record written has the iteration number as its index, and contains the
complete state of the program at that time (eg, all the parameters and
hyperparameters of the network being trained).

Note that log files contain binary data; they are not human-readable.

After an iterative program finishes, the user may decide to let the
run continue for more iterations.  This is easily done by just
invoking the program again with a larger iteration limit, whereupon it
restarts using the last state stored in the log file, and then appends
records to the log file for further iterations.

The information about iterations that is stored in the log file can be
examined using various programs both during and after a run.  In
particular, the user can plot the progress of various quantities
during the course of the run, without having to decide beforehand
which quantities will be of interest.  The states saved at various
iterations are also the basis for making Monte Carlo estimates, and in
particular, for making Bayesian predictions based on a sample of
networks or Gaussian processes from the posterior distribution.


Models and data

The 'util' directory also contains modules and programs that specify
the final portion of a probabilistic model (which is independent of
the details of networks or other functional schemes), that support
reading of numeric input from data files or other sources, and that
specify sets of training and test cases for supervised learning
procedures (such as those based on multilayer perceptron networks).

The models supported include those for regression, classification, 
and survival analysis.  The survial analysis models were recently
implemented, and should be regarded as experimental.  See
model-spec.doc for details

The data files used must contain numbers in standard ASCII form, with
one line per case, but there is considerable freedom regarding
separators and in the ordering of items.  "Input" and "target" items
that pertain to a case may come from the same file, or different
files, and the position within a line of each item may be specified
independently.  The set of cases (lines) to be used for training or
testing can be specified to be a subset of all the lines in a file.
The data source can also be specified to be the output of a program,
rather than a data file.

Specifications for where the training and test data comes from are
written to a log file by the 'data-spec' program, which also allows
the user to specify that certain transformations are to be done to the
data items before they are used.  In particular, the data can be
translated and re-scaled in a user-specified way, or by amounts that
are automatically determined from the training data.

The source of "test" data can also be specified explicitly by
arguments to the relevant commands, allowing the final results of
learning to be applied to any data set for which predictions are
desired.

See data-spec.doc for details on how all this is specified.


Random number generation

A scheme for combining real and pseudo random numbers is implemented
by modules in the 'util' directory, along with procedures for sampling
from various standard distributions, and for saving the state of the
random number generator.

The 'rand-seed' program is used to specify a random number seed to use
for a run.  The state of the random number generator is saved with
each iteration in the log file in order to ensure that resuming a run
produces the same results as if the run had continued without
stopping.


Markov chain Monte Carlo

The 'mc' directory contains modules and programs that support the use
of Markov chain Monte Carlo methods.  A Markov chain Monte Carlo
application is created by adding modules that compute certain
application-specific quantities, of which the most central is the
probability distribution to sample from.  For example, the neural
network application provides a procedure for computing the posterior
probability density of the network parameters.  An application may
also provide implementations of specialized sampling procedures, such
as the procedures for doing Gibbs sampling for hyperparameters in the
neural network application.

A variety of Markov chain methods are supported by the 'mc' system,
including some that are not of much use in the neural network and
Gaussian process applications.  In particular, the "tempering" methods
are not currently implemented for the neural networks or Gaussian
processes, though they may be in future.  Users interested only in
neural networks or Gaussian processes should therefore ignore the
tempering facilities (such as the 'mc-temp-sched' and 'mc-temp-filter'
programs).

For the user of neural network or Gaussian process models, the most
important 'mc' program is 'mc-spec', which is used to specify how the
Markov chain sampling is to be done.  There are a large number of
reasonable ways of sampling for neural networks or Gaussian processes.
The best way is still the subject of research.  Good results can be
obtained using several standard approaches, however, as described in
the examples in other sections of this documentation.  You can also
read all about the various methods in mc-spec.doc.


Neural network models

The 'net' directory contains the modules and programs that implement
Bayesian learning for models based on multilayer perceptron networks,
making use of the modules in the 'util' and 'mc' directories.  The
networks and data models supported are as described in my book,
Bayesian Learning for Neural Networks, with the addition of
experimental models for survival analysis.

A network training run is started with the 'net-spec' program, which
creates a log file to which it writes specifications for the network
architecture and priors.  In a simple run, the 'model-spec',
'data-spec' and 'mc-spec' programs would then be used to specify the
way the outputs of the network are used to model the targets in the
dataset, what data makes up the training set (and perhaps the test
set), and the way the sampling should be done.  The 'net-mc' program
(a specialization of the generic 'xxx-mc' program) would then be
invoked to do the actual sampling.  Finally, the 'net-pred' program
would be used to make predictions for test cases based on the networks
saved in the log file.

Usually, one would want to see how the run had gone before making
predictions.  The 'net-display' program allows one to examine the
network parameters and hyperparameters at any specified iteration.
The 'net-plt' program can be used to obtain the values of various
quantities, such as the training set error, for some range of
iterations.  The output of 'net-plt' would usually be piped to a
suitable plot program for visual examination, though it is also
possible to directly look at the numbers.

Several other programs are also present in the 'net' directory.  Some
of these will probably not be of interest to the ordinary user, as
they were written for debugging purposes, or to do specialized tasks
relating to my thesis.


Gaussian process models

The 'gp' directory contains the modules and programs that implement
Bayesian inference for Gaussian process models, making use of the
modules in the 'util' and 'mc' directories.  These Gaussian process
programs are analogous to the neural network programs.  The models
based on Gaussian processes are also similar to models based on large
neural networks using Gaussian priors (or other priors with finite
variance).

To start, the 'gp-spec' program is used to specify a Gaussian process
model - that is, to specify the form of the covariance function, and
the priors on the hyperparameters that control this covariance
function.  The 'model-spec' and 'data-spec' programs are then be used
to specify how the Gaussian process is used to model data, and the
source of the training data (and possibly test data).  The Markov
chain sampling method is then specified using 'mc-spec', and sampling
is done using 'gp-mc'.  Finally, 'gp-pred' is used to make predictions
for test cases using the Gaussian processes that were saved in the log
file by 'gp-mc'.

The 'gp-display' and 'gp-plt' programs can be used to view the
Gaussian processes generated by 'gp-mc', both during and after the
run.  Several other programs in the 'gp' directory may also be of
interest.


Quantities obtainable from log files

The 'xxx-plt' programs (eg, 'net-plt' and 'gp-plt') are the principal
means by which simulation runs are monitored.  These programs allow
one to see the values of various "quantities", evaluated for each
iteration stored in a log file within some range.  Some other programs
(eg, 'xxx-hist') also use the same set of quantities.

A quantity is specified by an identifying character, perhaps with a
numeric modifier.  Some quantities are single numeric values
(scalars); others are arrays of values, in which case the desired
range of values is also specified following an "@" sign.  Some
quantities can be either scalars or arrays, depending on whether a
range specification is included.

There is a hierarchy of quantities, as defined by modules at different
levels.  A few quantities are universally defined - principally 't',
the index of the current iteration.  Many more are defined for any
Markov chain Monte Carlo application - such as 'r', the rejection rate
for Metropolis or Hybrid Monte Carlo updates.  A large number of
quantities specific to neural networks or to Gaussian processes are
also defined - for example, 'b', the average squared error on the
training set, and 'n', the current value of the noise standard
deviation (for a regression model).  For details, see quantities.doc,
mc-quantities.doc, net-quantities.doc, and gp-quantities.doc.


EXAMPLES OF BAYESIAN MODELING WITH NEURAL NETWORKS AND GAUSSIAN PROCESSES

This section shows how Bayesian inference for models based on neural
networks and Gaussian processes can be done for three simple synthetic
problems.

The output shown below was obtained by running the software on our
machine, with ">" at the start of a line indicating a command line
that was input.  It is possible (even likely) that your results will
differ, even if you have installed the software correctly, since small
differences in floating point arithmetic can be magnified into large
differences in the course of the simulation.  However, unless one of
the simulations became stuck in an isolated local mode, the final
predictions you obtain from 'net-pred' for 'gp-pred' should be close
to those reported below.

All the data sets mentioned here are present in the 'examples'
sub-directory, along with the C source of the programs that generated
them.  It is assumed below that you have changed to this directory.
The command sequences for running the simulations that are mentioned
below are also stored in this directory, in shell files with the names
'rcmds.net', 'rcmds.gp', 'bcmds.net', 'bcmds.gp', 'ccmds.net', and
'ccmds.gp'.

Note that the particular network architectures, priors, and Markov
chain sampling options used below are only examples of reasonable
choices.  There are many other possibilities that are also reasonable.
To gain a full understanding of the various possibilities, and their
advantages and disadvantages, you will need to read both the general
references given earlier for these models, and the detailed
documentation in the ".doc" files.


A SIMPLE REGRESSION PROBLEM

As a first example, we will look at a simple regression problem, 
in which there is one real-valued input for each case, and one
real-valued target, whose value is to be predicted.

I generated synthetic data of this type in which the input variable,
x, for each case had a standard Gaussian distribution and the
corresponding target value came from a Gaussian distribution with
standard deviation 0.1 and mean given by

         0.3 + 0.4*x + 0.5*sin(2.7*x) + 1.1/(1+x^2)

I generated 200 cases in total, stored in the file 'rdata'.  Each case
consists of a line containing first the input value and then the
target value.  The first 100 of these cases are meant for training,
nand the second 100 for testing.


A neural network model for the regression problem.

We will model this data using a multilayer perceptron with one input
unit, one hidden layer of eight tanh units, and a single output unit
whose activation function is the identity.  The value of the output
unit will be taken as the mean of a Gaussian distribution for the
target, with the standard deviation of this Gaussian (the noise level)
being a hyperparameter to be estimated along with the parameters of
the network.  We will also use hyperparameters to express the prior
distributions for the network parameters.  Specifically, we will use
one hyperparameter for the input-to-hidden weights, one for the hidden
unit biases, and one for the hidden-to-output weights.  The output
unit bias will be given a simple Gaussian prior, with no adjustable
hyperparameter.  (The role of hyperparameters is primarily to
introduce dependencies between parameters, so they are usually not
used when they would control just a single parameter.)

The first step in applying this model to the data is to create a log
file containing the specifications for the network architecture and
the priors to use for the network parameters.  This can be done using
the following command:

    > net-spec rlog.net 1 8 1 / - 0.05:0.5 0.05:0.5 - x0.05:0.5 - 100

Here, "rlog.net" is the name of the new log file, and the arguments
"1", "8", and "1", specify the numbers of input, hidden, and output
units.  Following the "/", the priors for the various groups of
network parameters are given, with a "-" indicating that a parameter
group should be omitted (equivalent to the parameters being zero).
The order of the groups is a bit hard to remember, but you can get a
summary easily by just invoking 'net-spec' with no arguments.  The
groups in the above command that are not omitted are the input-hidden
weights, the hidden biases, the hidden-output weights, and the output
bias.

In general, the prior specifications used in the net-spec command
consist of a "width" value followed by up to three "alpha" values,
with perhaps an option character tacked on to the front.  For the full
details, see Appendix A of my thesis and prior.doc.  Here, I will just
comment on the particular priors used above.

The prior specification used for the output bias is simply "100",
which means that the bias has a Gaussian prior with mean zero and
standard deviation 100.  The prior specifications of the form
"0.05:0.5" indicate that the parameters in these groups are associated
with a hyperparameter, which gives the standard deviation of a
Gaussian prior for these parameters.  The hyperparameter itself has a
rather vague prior that spans several orders of magnitude around one.
The inverse gamma priors used are somewhat difficult to visualize,
because their tails are asymmetrical, but some standard choices are
often appropriate.  Here, the "0.5" after the colon controls how vague
the prior is (closer to zero is more vague).  The "0.05" specifies the
location of this vague distribution, but due to the asymmetry of the
tails, it is closer to being the lower limit of the prior than the
centre (for vague priors such as this). 

The "x" in front of the prior for the hidden-to-output weights
indicates that the prior should be automatically rescaled based on the
number of hidden units, so as to produce an effect that is independent
of the number of hidden units (in the limit of large numbers).

Once the network has been specified, we need to say how the network
outputs will be used to model the targets (response variables) in the
data set.  We do this with the 'model-spec' command:

    > model-spec rlog.net real 0.05:0.5

In this case, the targets are real-valued, and are modeled as the
network output plus Gaussian noise, with the noise standard deviation
being a hyperparameter having the prior given by the last argument of
the command.  The syntax of the prior specification is the same as 
for the priors on network parameters.

You can view the architecture and prior specifications stored in the
log file by invoking 'net-spec' with just a log file argument.  In
this example, this should give the following result:

    > net-spec rlog.net
    
    Network Architecture:
    
      Size of input layer:    1
      Sizes of hidden layers: 8
      Size of output layer:   1
    
      Data model: real
    
    
    Prior Specifications:
    
             Hidden Layer 0
    
      Input-Hidden Weights:    0.050:0.50
      Hidden Biases:           0.050:0.50
    
             Output Layer
    
      Hidden0-Output Weights: x0.050:0.50
      Input-Output Weights:    0.050:0.50
      Output Biases:           100.000

You can also view the model specification by invoking 'model-spec'
with just one argument giving the log file.

Once the network and data model have been specified, we need to
specify the data sets to be used for training and (optionally) for
testing.  We do this using the 'data-spec' command:

    > data-spec rlog.net 1 1 / rdata@1:100 . rdata@101:200 .
    Number of training cases: 100
    Number of test cases: 100

Here, "rlog.net" is the log file we created with 'net-spec', to which
the data specifications will be appended.  The "1" and "1" arguments
give the numbers of inputs and targets.  These must be consistent with
the network architecture (if not, an error will be reported later when
you try to start the training).

After the "/", specifications for where to get the training and test
data are given.  Each such specification consists of two parts: the
source for the inputs, and the source for the targets.  The
specification "rdata@1:100" means that the training inputs come from
the file 'rdata', in lines 1 to 100, while the specification of
"rdata@101:200" for the test inputs indicates that they also come from
the file 'rdata', but in lines 101 to 200.  In the above command, the
sources for the targets are given as just ".", which means the target
items are on the same lines as the inputs, following the last input
item.  We could have said that the targets come from a completely
different file, however.  It is also possible to specify exactly where
on a line the inputs and targets are located (and hence to ignore some
items in the file).  For documentation on these and other features,
see numin.doc.

Though it is not done above, the 'data-spec' command also allows you
to specify transformations to be applied to the inputs or targets
before they are used.  This is useful, for example, if you wish to use
inputs that have been "normalized" to have mean zero and variance one,
based on the training data.  See data-spec.doc for the details.

In the training runs reported in the thesis, I used a short "initial
phase" to get things started, followed by a long "sampling phase" to
bring the simulation to equilibrium and then produce a sample of
networks from the posterior for use in prediction.  I still use the
same general procedure, but with some changes to how the initial phase
is done.

It seems desirable to start the simulation in a state where the
hyperparameters take on moderate values, and leave them fixed for a
few iterations so that the network parameters will also take on
moderate values.  This can be accomplished using the following
commands:

    > net-gen rlog.net fix 0.5
    > mc-spec rlog.net repeat 10 sample-noise heatbath hybrid 100:10 0.2
    > net-mc rlog.net 1

The 'net-gen' command stores a network in the log file with index
zero, in which the hyperparameters have values of 0.5, and the network
parameters are zero.  This is the initial state of the simulation run.
The following 'mc-spec' command specifies the Markov chain operations
to be performed in the initial phase.  Here, each iteration consists
of ten repetitions of the following steps:  Gibbs sampling for the
noise level, a heatbath replacement of the momentum variables, and a
hybrid Monte Carlo update with a trajectory 100 leapfrog steps long,
using a window of 10, and a stepsize adjustment factor of 0.2.  Note
that the hyperparameters are not updated, and hence will remain fixed
at values of 0.5.  Finally, a single such iteration is done by calling
'net-mc' with an iteration limit of 1.

The stepsize adjustment factor of 0.2 used above is typical of what is
needed, but will not be appropriate in all circumstances.  After the
'net-mc' command has finished, the number of the 10 hybrid Monte Carlo
updates that were rejected can be determined using the command
'net-plt t r rlog.net', which will write the iteration number (of 1)
and the rejection rate on standard output.  If the rejection rate is
high (say, over 0.3), a new run should be done using a smaller
stepsize adjustment factor.  In the initial phase, one would generally
start by guessing a value for the stepsize adjustment factor that is
on the low side, since there is no point in optimizing this choice.

At this point, we hope to have a network stored in the log file (with
index 1) that has values for both the parameters and hyperparameters
that are of moderate magnitude, and which have adapted at least
somewhat to the training data.  We can now start serious sampling with
the following commands:

    > mc-spec rlog.net sample-sigmas heatbath hybrid 1000:10 0.4
    > net-mc rlog.net 100

The 'mc-spec' command appends a new set of Markov chain operations to
the log file, which will override the previous set.  These operations
are Gibbs sampling for both the hyperparameters and the noise level
(the "sigmas"), a heatbath update for the momentum variables, and a
hybrid Monte Carlo update with a trajectory 1000 leapfrog steps long,
a window of 10, and a stepsize adjustment factor of 0.4.  A long
trajectory length is typically desirable for the sampling phase.  As
in the initial phase, the stepsize adjustment factor of 0.4 used is
typical, but not universally applicable.  It may pay at this stage to
experiment in order to find out how large this factor can be while
keeping the rejection rate low.  The use of a "window" of around 10
states costs little and is often beneficial.

The 100 iterations of the sampling phase started with the command
'net-mc rlog.net 100' will take a while to complete (about four
minutes on our current SGI machine).  If you put the command in the
background (or add a '&' to the end of the 'net-mc' command), you will
be able to monitor progress while you wait.  For example, you can look
at the last network saved in the log file (or any earlier one) using
'net-display'.  After half a minute or so, you might see the following:

    > net-display rlog.net
  
    Network in file "rlog.net" with index 15
    
    Input to Hidden Layer 0 Weights [1]
    
     3.36 3.36: -1.24  +1.73  -4.04  -0.24  +2.49  -2.95  -1.56  -3.21
    
    Hidden Layer 0 Biases [2]
    
          1.90: -1.58  -3.59  +4.42  +0.85  -4.59  -3.69  +2.03  -0.40
    
    Hidden Layer 0 to Output Weights [3]
    
     0.76 0.76: -1.23
    
          0.76: +1.04
    
          0.76: +0.34
    
          0.76: -0.38
    
          0.76: -0.24
    
          0.76: +0.80
    
          0.76: +0.52
    
          0.76: -0.56
    
    Output Biases [4]
    
        100.00: +1.10
    
    Noise levels
    
       0.08 -  0.08

This display of network parameters and hyperparameters is divided into
sections for different parameter groups.  Within each section, the
numbers before the colons are hyperparameters, those after are
parameters (weight and biases).  There are more hyperparameters shown
than were mentioned earlier, but for this network architecture, the
extra hyperparameters are either fixed in value (the 100 for output
biases), or tied to the value of a higher-level hyperparameter, so
they are effectively not present.

The parameter groups in the 'net-display' output are identified by
numbers in square brackets.  These can be used with the 'h', 'w', 
and 'W' quantities of 'net-plt'.  For example, to see how the
hyperparameter controlling the hidden-to-output weights has changed
during the simulation (so far), one can use the command

    > net-plt t h3 rlog.net | plot

where 'plot' is some suitable plot program.  (One can also just invoke
net-plt and look at the numbers printed on standard output.)  Here
'h3' refers to the top-level hyperparameter for group 3, which is seen
in the output of 'net-display' above to be the hidden-to-output group.

By looking at plots of the hyperparameters and quantities such as the
squared error on the training set ('b'), one can get an idea of when
the simulation has reached equilibrium.  Networks from that point on
can then be used to make predictions for test case using the
'net-pred' program.  Often, it will not be completely clear that
equilibrium has been reached until the simulation has been allowed to
proceed for quite a long time, but predictions based on shorter runs
may nevertheless be quite good.

For this problem, let's assume that we have decided to discard the
first 20 iterations as perhaps not coming from the equilibrium
distribution.  The following command will use the networks from the
remaining 80 iterations to produce predictions for all test cases, and
report the average squared error:

    > net-pred itn rlog.net 21: 

    Number of networks used: 80

    Case  Inputs  Targets  Means   Error^2

       1    0.92    1.49     1.59  0.0093
       2    0.71    1.83     1.79  0.0012
       3    0.20    1.72     1.67  0.0021
       
            ( midde lines omitted )
    
      98   -0.69    0.35     0.35  0.0000
      99   -1.33    0.19     0.36  0.0277
     100   -0.09    1.31     1.24  0.0052

    Average squared error guessing mean:   0.01035+-0.00147

The options "itn" specified ask for a listing of the inputs ("i") and
targets ("t") for each case, along with the mean ("n") output for that
case of the 80 networks used for prediction.  The squared error when
using this mean to predict the target is shown for each case, and the
average squared error for the test cases is shown at the bottom, along
with its standard error with respect to the random selection of test
cases.  Considering that the average squared error with optimal
prediction is 0.01 (due to the noise of standard deviation 0.1 added
when generating the data), the network model has done quite well, as
one would hope it would on an easy problem such as this.

It is also possible to get predictions for cases that are not in the
test set that was specified with 'data-spec'.  For example:

    > net-pred nb rlog.net 11: / "%echo 2.3"
        1.37

Here, the options "nb" ask for only the predictive mean, with "bare"
output (no headings).  The argument at the end says that the inputs
for test cases (here, just one case) should be taken from the output
of the Unix command "echo 2.3", which just outputs the number 2.3.


A Gaussian process model for the regression problem.

We can also model this data using a Gaussian process.  Such a model is
similar to a network model with an infinite number of hidden units.
The weights in this hypothetical infinite network are not represented
explicitly (fortunately, since this would require an infinite amount
of memory).  Only the hyperparameters are explicitly represented.

A Gaussian process model is specified using the gp-spec command, which
is analogous to the net-spec command.  For the simple regression
model, the following is one appropriate specification:

    > gp-spec rlog.gp 1 1 100 0.05:0.5 / 0.05:0.5 0.05:0.5

Here, "rlog.gp" is the name of the new log file that will hold the
results of the Gaussia process run.  The first two arguments following
the log file are the numbers of inputs and outputs, respectively, both
"1" for this problem.

The (optional) argument of "100" that follows is the priors for the
constant part of the covariance function used.  This corresponds to
the prior for the output unit bias in a network model.  A
specification for a linear part of the covariance could follow (but
doesn't here); it would correspond to a prior for direct input-output
connections in a network.  For reasons of computational accuracy, it
is best not to use too vague a prior for the constant part of the
covariance, even though that would not usually be a problem from a
statistical point of view.

The remaining arguments (after the "/") give the priors for the
hyperparameters used in an exponential term of the covariance
function.  These priors correspond to those for the hidden-output and
input-hidden weights in a network model.  (There is no counterpart
here to the prior for the hidden unit biases in a network model.)  The
first prior is for the scale of this term, which controls the
magnitude of the non-linear variation in the function.  The second
prior is for the relevance of the input, which controls the amount by
which the input has to change to produce a change in the non-linear
component of the function that is comparable to the overall scale over
which this component varies.  The prior specifications are in the same
form as is used for network specifications (see prior.doc).  The
specifications of "0.05:0.5" used here are vague, allowing these
hyperparameters to take on values over a wide range.

The specification can be viewed by invoking 'gp-spec' with just the
name of the log file:

    > gp-spec rlog.gp
    
    Number of inputs:    1
    Number of outputs:   1

    Constant part of covariance:  100.000

    Exponential parts of covariance:

       Scale           Relevance            Power

       0.050:0.50      0.050:0.50           2.000

Once the Gaussian process model for functions has been specified, we
can specify how the function values are used to model the targets in
the dataset using 'model-spec', in exactly the same was as for a
network model:

    > model-spec rlog.gp real 0.05:0.5

We also say where the training and (optionally) the test data comes
from using 'data-spec':

    > data-spec rlog.gp 1 1 / rdata@1:100 . rdata@101:200 .

The model and data specifications can be viewed by invoking these
programs with just the name of a log file.

We are now ready to sample from the posterior distribution of the
hyperparameters for the Gaussian process model.  To start, we can fix
the hyperparmeters at reasonable initial values, using 'gp-gen':

    > gp-gen rlog.gp fix 0.5 0.1

This fixes the scale hyperparameters to 0.5 and the relevance
hyperparameters to 0.1 (linear hyperparameters, if present, would be
fixed to the product of these).  By default, the hyperparameters are
set to the "width" value from their prior specification.  Because the
priors are often vague (as here), this may not be a very reasonable
starting point.

We now specify the Markov chain operations to be used in sampling.
There are a great many possibilities for these operations.  Here is
one reasonable method:

    > mc-spec rlog.gp heatbath hybrid 20:4 0.5

This uses hybrid Monte Carlo, with trajectories 20 leapfrog steps
long, with a window of 4 states.  The stepsize adjustment factor used
is 0.5.  If the rejection rate turns out to be too high (as can be
checked using the 'gp-plt t r rlog.gp' command), the stepsize should
be adjusted downward.

To peform these sampling operations 100 times, we use the following
command:

    > gp-mc rlog.gp 100

We can let this run in the background (eg, by adding '&' to the end of
the command), and use 'gp-plt' or 'gp-display' to monitor progress.
The quantities that can be plotted with 'gp-plt' are similar to those
that can be plotted using 'net-plt', except that quantities relating
to test cases have been omitted, since they would often take a long
time to compute (the 'E' and 'H' quantities, defined in the "mc"
module, may also take a long time).  See gp-quantities.doc for
details.

Once the gp-mc run has completed (which takes about two minutes on
our SGI machine), the iterations from the latter part of the run can
be used to make predictions for test cases.  This is done using
'gp-pred', which operates much like 'net-pred'.  The following command
makes predictions for the test cases based on the last 80 of the 100
iterations, and reports the average squared error:

    > gp-pred na rlog.gp 21:

    Number of iterations used: 80

    Number of test cases: 100

    Average squared error guessing mean:   0.00972+-0.00131

This takes only a few seconds on our machine.  Predictions will take
longer when the number of training cases is larger, or if the median
or log probability are to be found (options "d" or "p" of 'gp-pred').
As can be seen, the performance of the Gaussian process model is quite
similar to that of the neural network model for this problem.  (The
difference in average performance seen is probably not significant,
considering the standard errors.)

The predictions for test cases made above are found directly from the
covariances between the targets in the training cases and the unknown
target in a test case.  The values of the regression function for the
training cases are never explicitly found.  Consequently, it is not
possible to plot quantities such as the squared error on training
cases over the course of the run.  To plot such quantities, you will
have to ask for the function values for training cases to be generated
in each iteration.  This takes a significant amount of time, and can
potentially cause numerical problems, which is why gp-plt won't just
do it as needed.

If you want to be able to plot the squared error on training cases (or
similar quantities such as case-by-case likelihoods), you will need to
change the 'mc-spec' command to the following:

    > mc-spec rlog.gp2 discard-values heatbath hybrid 20:4 0.5 sample-values

The "sample-values" operation at the end generates function values for
all the training cases, which will be stored in the log file.  These
values can later be used to compute the squared error for training
cases, which can be plotted with a command such as

    > gp-plt t b rlog.gp2

The "discard-values" operation throws away the function values (if
present) before the operations for updating hyperparameters.  Throwing
away information may seem wasteful, but it actually improves
convergence in this context.

Unfortunately, if you make only this change, you will probably get the
following error message when you try to run 'gp-mc':

  Couldn't find Cholesky decomposition of posterior covariance in sample-values!

This message is produced when the round-off error in the matrix
computations used by "sample-values" is enough to turn the results
into nonsense.  The problem is due to the poor "conditioning" of the
covariance matrix.  Roughly speaking, the covariances between
neighbouring training cases are so high that knowing all but one
function value is enough to determine the remaining function value to
a precision comparable to the level of round-off error.

To fix this, the conditioning of the covariance matrix must be improved.
Changing the 'gp-spec' command as follows is sufficient on our machine:

    > gp-spec rlog.gp2 1 1 10 - 0.01 / 0.05:0.5 0.05:0.5

There are two changes here from the 'gp-spec' command used before.
First, the constant part of the covariance has been reduced from 100
to 10, which in fact makes little difference for this problem.  Since
arithmetic is done in floating point, this increases the effective
precision of the covariances.  Second, the covariance now includes a
"jitter" part of 0.01 (the "-" preceding this indicates that there is
still no linear part).  Jitter is much like noise, in that it varies
independently from one case to another, but it is considered part of
the function value, which noise is not.  The jitter makes all the
function values less predictable, reducing the problem of poor
conditioning.  Jitter plays a more crucial role for binary and class
models.
1

A PROBLEM WITH A BINARY RESPONSE

As a second example, I generated a data set with two real-valued
inputs, x1 and x2, and a binary target.  The inputs were drawn
independently from standard Gaussian distributions.  The target was
then set to "1" with the following probability:

    exp ( - ((x1-0.4)^2 + (x2+0.3)^2) ^ 2 )

ie, the negative exponential of the fourth power of the distance of
(x1,x2) from (0.5,-0.3).  I generated 500 cases, and used the first
300 for training and the remaining 200 for testing.


A neural network model for the binary response problem.

For this problem, we can again try using a network with one layer of
hidden units (fifteen for this problem), and a single output unit.
For a binary target, a Gaussian data model would be inappropriate;
instead, we can use a logistic regression model, in which the
probability of the target being "1" is obtained by passing the value
of the output unit through the logistic function, f(x)=1/(1+exp(-x)).

The network, model, and data specification commands needed are quite
similar to those used in the regression problem above:

    > net-spec blog.net 2 15 1 / - 0.05:0.5 0.05:0.5 - x0.05:0.5 - 100 
    > model-spec blog.net binary
    > data-spec blog.net 2 1 2 / bdata@1:300 . bdata@301:500 .
    Number of training cases: 300
    Number of test cases: 200

The 'net-spec' command differs only in the number of input units (2),
the number of hidden units (15).  The data model used is "binary",
with no need for a noise level prior.

The 'data-spec' command also says that there are two inputs, and one
target.  It also has a third argument of "2" just before the "/",
which indicates that the target must be an integer with two possible
values (which are "0" and "1").

The initial phase commands that were used for the simple regression
problem turn out to be adequate for this problem as well:

    > net-gen blog.net fix 0.5
    > mc-spec blog.net repeat 10 sample-noise heatbath hybrid 100:10 0.2
    > net-mc blog.net 1

For the sampling phase, we could also try using commands similar to
those presented above, but we might as well try something different
(the mc-spec command needed here is long, so it is continued by
putting a "\" at the end of the first line):

    > mc-spec blog.net repeat 10 sample-sigmas heatbath 0.95 \
                             hybrid 100:10 0.3 negate
    > net-mc blog.net 200

The above 'mc-spec' command specifies the variant of hybrid Monte
Carlo with "persistence" in which relatively short trajectories are
used, but random walks are suppressed by only partially replacing the
momentum in the 'heatbath' step.  Note that for this to work well, the
rejection rate must be quite small.  This alternative method has the
advantage that it allows for more frequent hyperparameter updates
(with 'sample-sigmas').

On our SGI machine, the 200 iterations requested above take about 45
minutes.  During this time, one can monitor the simulation, for
instance with the command:

    > net-plt t h1h2h3 blog.net | plot

where again, 'plot' is some appropriate plotting program, which in
this case must be capable of plotting three superimposed graphs, for
the three hyperparameters h1, h2, and h3.  The values for these
hyperparameters exhibit quite a high degree of autocorrelation, which
is why it is advisable to allow the simulation to go for 200
iterations, in order to be more confident that the simulation has
explored all high-probability regions of the posterior distribution.

Once the run has finished, we can make predictions using 'net-pred',
based, say, on the networks from the final 3/4 of the run (which is a
generally reasonable portion).  For a problem such as this, where the
response is binary, we are most likely interested in guessing whether
the target is "0" or "1", with performance measured by how often we
are right.  We can get such predictions as follows:

    > net-pred itm blog.net 51: 

    Number of networks used: 150

    Case  Inputs         Targets  Guesses  Wrong?

       1   -1.56   0.90    0.00       0       0
       2    0.09  -0.13    1.00       1       0
       3   -0.79   0.85    0.00       0       0
       
               ( midde lines omitted )
    
     198    1.49   0.70    0.00       0       0
     199   -2.23  -0.28    0.00       0       0
     200   -0.91  -0.03    0.00       0       0

    Fraction of guesses that were wrong:  0.0900+-0.0203

The "itm" options ask for output listing the inputs, the targets, and
the guesses based on the mode of the predictive distribution.  A
summary is also printed that reports the fraction of guesses that were
wrong, along with the standard error for this estimate of the error
rate.


A Gaussian process model for the binary response problem.

This binary data can be modeled using a Gaussian process as well.  The
Gaussian process specifies a distribution over real-valued functions.
The function value for the inputs in a particular case can be passed
through the logistic function, f(x) = 1/(1+exp(-x)), to give the
probability that the target in that case will be '1' rather than '0'.

The specifications for a Gaussian process model analogous to the
network model used above are as follows:

    > gp-spec blog.gpl 2 1 1 - 0.1 / 0.05:0.5 0.05:0.5
    > model-spec blog.gpl binary
    > data-spec blog.gpl 2 1 2 / bdata@1:300 . bdata@301:500 .
    Number of training cases: 300
    Number of test cases: 200

The 'gp-spec' command used here does not quite correspond to the
'net-spec' command used above.  The following command would give a
closer correspondence:

    > gp-spec blog.gpl 2 1 100 / 0.05:0.5 0.05:0.5

The reason for modifying this, by reducing the constant part of the
covariance (from 100 to 1) and introducing a small (0.1) "jitter"
part, is to solve computational problems of poor conditioning and slow
convergence.  The "jitter" part lets the function value vary randomly
from case to case, as if a small amount of Gaussian noise were added.
This makes the function values less tightly tied to each other, easing
the computational difficulties (with the unmodified specification,
'gp-mc' would probably work only if the dataset was very small).
These changes have little effect on the statistical properties of the
model, at least for this problem.

Sampling might now be done using the following commands:

    > gp-gen blog.gpl fix 0.5 1
    > mc-spec blog.gpl repeat 4 scan-values 200 heatbath hybrid 6 0.5
    > gp-mc blog.gpl 50

These commands (and variations on them) are similar to those that you
might use for a regression problem, except that a "scan-values 200"
operation has been included.  This operation performs 200 Gibbs
sampling scans over the function values for each training case.  
An explicit representation of function values is essential for a
binary model, though not for a simple regression model, because the
relationship of function values to targets is not Gaussian.
Unfortunately, for the very same reason, the direct "sample-values"
operation is not available, so Gibbs sampling must be done.

The 50 sampling iterations take about 50 minutes on our SGI machine.
While you wait, you can check the progress of the hyperparameters
using gp-display:

    > gp-display blog.gpl

    GAUSSIAN PROCESS IN FILE "blog.gpl" WITH INDEX 10

    HYPERPARAMETERS

    Constant part:

          1.000

    Jitter part:

            0.1

    Exponential parts:

          6.657
          0.179 :      0.179      0.179

Note that there are only two variable hyperparameters, since the
constant and jitter parts are fixed, and the relevance hyperparameters
for each input are tied to the higher-level relevance hyperparameter.
A time plot of two variable hyperparameters can be obtained as follows:

    > gp-plt t S1R1 blog.gpl | plot

Once sampling has finished, predictions for test cases can be made
using 'gp-pred'.  The following command prints only the average
classification performance:

    > gp-pred ma blog.gpl 21:%2

    Number of iterations used: 15

    Number of test cases: 200

    Fraction of guesses that were wrong:  0.0900+-0.0203

This takes about one minute on our SGI machine.  This is considerably
slower than prediction using a network model, since a covariance
matrix must be inverted for each iteration used (saving the inverses
for each iteration would take up lots of disk space).  The accuracy
achieved is about the same as the network model, which is not too 
surprising, given that they both use a logistic function to relate
function values to target probabilities.

It is possible to define a Gaussian process model that will behave as
what is known is statistics as a "probit" model rather than a
"logistic" model.  This is done by simply setting the amount of jitter
to be large compared to the span over which the logistic function
varies from nearly 0 to nearly 1.  This can be done by changing the
'gp-spec' command to the following, in which the jitter part is 10
(the constant part is also changed to be of the same magnitude):

    > gp-spec blog.gpp 2 1 10 - 10 / 0.05:0.5 0.05:0.5

One can then proceed as above.  The final performance is similar, but
the scale hyperparameter takes on much larger values.


A THREE-WAY CLASSIFICATION PROBLEM

I also created a synthetic data set for a three-way classification
problem.  Data items were generated by first drawing quantities x1,
x2, x3, and x4 independently from distributions uniform over (0,1).
The class of the item, represented by "0", "1", or "2", was then
selected as follows: if the two-dimensional Euclidean distance of
(x1,x2) from the point (0.4,0.5) was less than 0.35, the class was set
to "0"; otherwise, if 0.8*x1+1.8*x2 was less than 0.6, the class was
set to "1"; and if neither of these conditions held, the class was set
to "2".  Note that x3 and x4 have no effect on the class.  The class
selected by this procedure was the target value for the network; the
inputs available for use in predicting the class were not x1, x2, x3,
and x4 themselves, however, but rather these four values plus Gaussian
noise of standard deviation 0.1.  I generated 1000 cases in this way,
of which 400 were used for training and 600 for testing.


A neural network model for the three-way classification problem.

This example will illustrate the "softmax" model for target values in
a small set, and the Automatic Relevance Determination (ARD) prior for
input-to-hidden weights.  The network and model specifications used
were as follows:

    > net-spec clog.net 4 8 3 / - x0.2:0.5:0.5 0.05:0.5 - \
                                x0.05:0.5 - 0.05:0.5
    > model-spec clog.net class

This specifies a network with 4 input units, 8 hidden units, and 3
output units.  The output units have identity activation functions,
but their values are used in a "softmax" data model, in which the
probability for target i is exp(o_i) / SUM_j exp(o_j), where the o_j
are the values of the output units. 

The prior specified for input-to-hidden weights, "x0.2:0.5:0.5", has
two "alpha" values, indicating that there is both a high-level
hyperparameter controlling the overall magnitude of input-to-hidden
weights, and lower-level hyperparameters for each input unit, which
control the magnitudes of weights out of each input.  If some of the
inputs are irrelevant (as are the third and fourth inputs in this
problem), we hope that the corresponding hyperparameters will take on
small values, forcing the weights out of these inputs to be close to
zero, and thereby avoiding any damage to predictive performance that
could result from the inclusion of these irrelevant inputs. The prefix
of "x" causes the width of this prior to be automatically scaled
according to the number of inputs.  This is appropriate if the number
of highly relevant inputs is thought not to depend on the total number
of inputs.

We need to use the following data specification for this problem:

    > data-spec clog.net 4 1 3 / cdata@1:400 . cdata@401:1000 .
    Number of training cases: 400
    Number of test cases: 600

The arguments "4" and "1" are the numbers of input and target values.
The "3" before the "/" says that each target must be one of the
integers "0", "1", or "2".  This "3" must match the number of softmax
output units specified in the network architecture, or an error will
result when training is started.

The initial and sampling phases of the simulation can be done using
the same approach as was used above for the binary data set (but the
"sample-noise" operation doesn't actually do anything here):

    > net-gen clog.net fix 0.5
    > mc-spec clog.net repeat 10 sample-noise heatbath hybrid 100:10 0.2
    > net-mc clog.net 1
    > mc-spec clog.net repeat 10 sample-sigmas heatbath 0.95 \
                                 hybrid 100:10 0.3 negate
    > net-mc clog.net 200

This takes about 65 minutes on our SGI machine.

We can see the effect of the ARD model by looking at the values of
the low-level input-hidden hyperparameters over the course of the
simulation, with the command:

    > net-plt t h1@ clog.net | plot

The third and fourth hyperparameters are much smaller than the first
two, indicating that ARD has done its job.

Predictions for test cases based on the predictive mode can now be
done in the same way as for the binary response problem.  If we are
interested only in the estimated classification performance, we can
use the following command:

    > net-pred ma clog.net 51:

    Number of networks used: 150

    Number of test cases: 600

    Fraction of guesses that were wrong:  0.1367+-0.0140

Here, the "a" option is used to suppress everything except the summary.


A Gaussian process model for the three-way classification problem.

Gaussian process models can also be used for multi-way classification
problems, in much the same way as for a binary response.  Here are
commands that implement a "probit" style model for the three-way
classification problem, using "persistent" hybrid Monte Carlo:

    > gp-spec clog.gpp 4 3 10 - 10 / 0.05:0.5 x0.2:0.5:1
    > model-spec clog.gpp class
    > data-spec clog.gpp 4 1 3 / cdata@1:400 . cdata@401:1000 .

    > gp-gen clog.gpp fix 0.5 1
    > mc-spec clog.gpp repeat 5 scan-values 100 heatbath 0.9 \
                                hybrid 1 0.4 negate
    > gp-mc clog.gpp 5
    > mc-spec clog.gpp repeat 5 scan-values 100 heatbath 0.99 \
                                hybrid 1 0.4 negate
    > gp-mc clog.gpp 100

For the first five iterations, the persistence is fairly small (0.9),
so that the high initial energy will be dissipated rapidly.  The
remaining iterations use a largers persistence (0.99) to suppress
random walks.  The run takes about 220 minutes on our SGI machine.
The n-cubed scaling of the computations for the Gaussian process
models leads to their becoming slower relative to neural network
models as the number of training cases increases.

Once the run is finished, predictions for test cases can be made
as illustrated below:

    > gp-pred itm clog.gpp 51:%5

    Number of iterations used: 10
    
    Case  Inputs                       Targets  Guesses  Wrong?
    
       1    0.29   0.90   0.74   0.33    2.00       2       0
       2    0.70   0.27   0.17   0.89    2.00       2       0
       3   -0.11   0.76   0.11  -0.02    2.00       2       0
       4    0.54   0.24   0.39   0.78    0.00       0       0

                      (middle lines omitted)

     597   -0.10   0.93   0.27   0.28    2.00       2       0
     598    0.14   0.19   0.08   0.70    1.00       1       0
     599    0.66   0.79   0.03   0.09    0.00       2       1
     600    0.76   0.90   0.73  -0.03    2.00       2       0
    
    Fraction of guesses that were wrong:  0.1333+-0.0139
    
This takes about 11 minutes on our SGI machine.

A "logistic" style model can be obtained by decreasing the jitter,
using a 'gp-spec' command such as the following:

    > gp-spec clog.gpl 4 3 1 - 0.1 / 0.05:0.5 x0.2:0.5:1

This model appears to convergence less rapidly than the probit model,
but gives similar results.


A REGRESSION PROBLEM WITH OUTLIERS

Finally, we will go back to the simple regression problem we started
with, but now some of the cases will be "outliers", for which the
noise is much greater than for normal cases.

In this synthetic data, the input variable, x, again had a standard
Gaussian distribution and the corresponding target value came from a
distribution with mean given by

         0.3 + 0.4*x + 0.5*sin(2.7*x) + 1.1/(1+x^2)

For most cases, the distribution about this mean was Gaussian with
standard deviation 0.1.  However, with probability 0.05, a case is an
"outlier", for which the standard deviation was 1.0 instead.

I generated 200 cases in total, stored in the file 'odata'.  The first
100 of these cases are meant for training, the second 100 for testing.
It is also possible to test on 'rdata', to see how well the function
learned predicts data that is never corrupted by high noise.


A neural network model for regression with outliers.

One way to model data with "outliers" is to let the noise level vary
from one case to another.  If the noise for the outlier cases is set
to be higher, they will end up having less influence on the function
learned, as is desirable.  The software allows the noise variance for
a case to vary according to an inverse gamma distribution.  This is
effectively the same as letting the noise have a t-distribution rather
than a Gaussian distribution.

The commands used to do this are as follows:

    > net-spec olog.net 1 8 1 / - 0.05:0.5 0.05:0.5 - x0.05:0.5 - 100 
    > model-spec olog.net real 0.05:0.5::4
    > data-spec olog.net 1 1 / odata@1:100 . odata@101:200 .

    > net-gen olog.net fix 0.5
    > mc-spec olog.net repeat 10 sample-noise heatbath hybrid 100:10 0.2
    > net-mc olog.net 1

    > mc-spec olog.net sample-sigmas heatbath hybrid 1000:10 0.4
    > net-mc olog.net 100

The crucial difference is in the 'model-spec' command, where the noise
prior of 0.05:0.5::4 specifies that the per-case noise precision
(inverse variance) follows a gamma distribution with shape parameter
of 4.  When this is integrated over, a t-distribution with 4 degrees
of freedom results.  This t-distribution is by no means an exact model
of the way the noise was actually generated, but its fairly heavy
tails are enough to prevent the model from paying undue attention to
the outliers.

The resulting model can be tested on data from the same source using
net-pred:

    > net-pred na olog.net 31:

    Number of networks used: 70

    Number of test cases: 100

    Average squared error guessing mean:   0.01943+-0.01129

One can also see how well the model does on the uncorrupted data that
was used originally:

    > net-pred na olog.net 31: / rdata@101:200 .

    Number of networks used: 70

    Number of test cases: 100

    Average squared error guessing mean:   0.00881+-0.00120

This is actually better than the results obtained earlier with the
model trained on uncorrupted data, though the observed difference is
probably not statistically significant.

In constrast, the results are substantially worse when the data with
outliers is used to train a standard model where the noise is Gaussian, 
with the same variance for each case.


A Gaussian process model for regression with outliers.

Gaussian process regression can also use a t-distribution for the
noise, specified using 'model-spec', as above.  Implementation of this
model requires sampling for function values in training cases, so a
small amount of "jitter" will almost always have to be included in the
covariance function.  A "sample-variances" operation must also be
specified in 'mc-spec', to allow the case-by-case noise variances to
be sampled.  The following commands illustrate how this is done:

    > gp-spec olog.gpt 1 1 1 - 0.001 / 0.05:0.5 0.05:0.5
    > model-spec olog.gpt real 0.05:0.5::4
    > data-spec olog.gpt 1 1 / odata@1:100 . odata@101:200 .

    > gp-gen olog.gpt fix 0.5 0.1
    > mc-spec olog.gpt sample-variances heatbath hybrid 20:4 0.5
    > gp-mc olog.gpt 200

This takes about six minutes on our SGI machine.  The progress of the
run can be monitored by examining the case-by-case noise standard
deviations in (say) the first 8 training cases, as follows:

    > gp-plt t v@0:7 olog.gpt | plot

Once the run has converged, a few of these standard deviations (for
cases that are outliers) should be much bigger than the others.  The
noise standard deviations can also be examined using the "-n" option
of 'gp-display'.

Predictions can be made using 'gp-pred':

    > gp-pred na olog.gpt 101:%5

    Number of iterations used: 20

    Number of test cases: 100

    Average squared error guessing mean:   0.01995+-0.01186

This performance is very similar to that of the network model.


HINTS AND WARNINGS

1) The error messages for invalid specifications of quantities for
   the plot programs are not very specific.  You should remember that
   quantities may be scalars or arrays, or sometimes either.  If the 
   quantity you want is an array, you have to include a "@" character.  
   To further complicate matters, some quantities take numeric modifiers,
   which are distinct from array indexes.  See quantities.doc and the 
   specific documentation on quantities for each application for more 
   details.

2) Some confusion is possible regarding hyperparameter values because
   they can be looked at in three ways:  as standard deviations (widths),
   as variances (squares of the standard deviations), and as precisions
   (inverse variances).  In particular, note that although the priors 
   for hyperparameters are described in terms of Gamma distributions for
   the precisions, their scale is specified in the net-spec and
   model-spec commands in terms of the corresponding standard deviations.

3) When there is a single output unit, a specification of the form
   "w:a:b" for the hidden-to-output weights is mathematically
   equivalent to one of the form "w:a::b".  The two specifications
   differ computationally, however.  In the "w:a:b" form, lower-level
   hyperparameters that each control a single weight are explicitly
   represented; with "w:a::b", equivalent hyperparameters exist
   mathematically, but are not represented explicitly.  The "w:a:b"
   form is probably to be preferred, since explicit hyperparameters 
   are of assistance to the heuristic procedure that chooses
   stepsizes for the dynamical updates.

4) Poor conditioning of matrix operations used for Gaussian processes
   can be a problem with the "sample-values" and "scan-values" operations, 
   and for the 'gp-eval' program.  The symptoms are error messages about
   Cholesky decompositions or matrix inversions not working.  Assuming 
   that these aren't due to bugs in the software, the solution is to
   improve the conditioning of the covariance matrix, hopefully without
   making the model depart to any significant degree from what you really
   wanted.  Conditioning can be improved in three main ways:
  
      a) Decrease the constant part of the covariance function.  There's
         almost never any reason for this to be greater than the range of
         the targets in the training cases.

      b) Increase the jitter part of the covariance.  For 'gp-eval' with
         the "targets" option, noise in the regression model acts the 
         same way as jitter.  Of course, increasing the jitter changes
         the model.

      c) Use a power less than 2 in an exponential part of the covariance.
         Poor conditioning results when the covariance has only constant, 
         linear, and exponential parts, with the exponential part having
         a power of 2 (the default), corresponding to smooth functions.  
         Decreasing the power makes the functions less smooth, and hence
         less predictable, which makes the matrix better conditioned.

      d) Use scan-values rather than sample-values.  The prior covariance
         matrix that is inverted in scan-values is probably less likely
         to be poorly conditioned than the posterior covariance matrix
         inverted in sample-values.  However, scan-values does not produce
         independent draws, so convergence may be slower.

5) If the system crashes in the middle of a run of 'net-mc', one can
   usually continue from the last iteration written to the log file 
   by just invoking 'net-mc' again with the same arguments (just as 
   one can continue for more iterations after 'net-mc' terminates 
   normally).  Problems could arise if the system crashed in the middle 
   of writing the records pertaining to an iteration, in which case some 
   fixup using 'log-copy' may be required.  Such problems could come
   either from a partial record at the end of the log file, or from
   a less-than-complete set of full records.  It is best to assess the 
   situation using 'log-records' before proceeding.

6) If you need to change the name of a program to avoid conflicts with 
   other programs you use, it is probably best to simply change the name 
   of the link in this software's 'bin' directory, leaving the name 
   unchanged in all the other directories.


GUIDE TO FURTHER DOCUMENTATION

The overview and examples above are intended just to get you started.
To use the software to do real work, you will probably need to refer
to the detailed documentation on the commands (and common aspects of
commands) contained in the files ending with ".doc" which are found in
the various sub-directories, and also all collected in the 'doc'
directory.  For quick reference, all commands print a brief summary of
the command syntax when they are invoked with no arguments.

In the syntax descriptions used, the characters "[" and "]" enclose
parts of the command that are optional, "{" and "}" enclose optional
parts that can be repeated, and "|" separates alternatives.  Except
for the command name (or other obvious keywords), the words in the
syntax descriptions are descriptive of what is to be entered, except
that words in quotes are to be entered literally (without the quotes).

The ".doc" files present in the various directories are listed below,
with the more important files marked by "*".  Programs listed as
"xxx-something" are generic, with "xxx" being replaced by the name of
an application (eg, "net", "gp", or "bvg").  In some cases, further
documentation is available under the specific name.

The file index.html is a hypertext index to this documenation.  It can
be accessed using a Web browser (eg, xmosaic or netscape), by a
command such as

    > xmosaic index.html

or by opening index.html as a local file in a browser that you are
already running. The index.html file must reside in the 'doc'
directory for this software.  One needn't start the browser from this
directory, however, provided one uses a full path name to identify
index.html.  The files accessed this way are .html files derived from
the .doc files.  The content is identical, except that references to
other .doc files have been converted into hypertext links that you can
follow with the browser.

All the introductory documentation (including this) is collected into
the 'manual' file.  You can print all the documentation by going to
the main directory for this software and issuing a command such as

  lpr doc/manual util/*.doc mc/*.doc net/*.doc gp/*.doc bvg/*.doc doc/rel*
 
(or using whatever command other than 'lpr' you use to print text files).


Generic utility programs [util]:

  * log             Facilities for handling log files
    log-types       Types of log file records used by various programs

    log-copy        Copy part of a log file to a new log file
    log-last        Display the index of the last record in a log file
    log-records     List all records in a log file  

  * data-spec       Specify data sets for training and testing
  * numin           Facilities for input of numeric data
    numin-test      Test numeric input module

  * model-spec      Specify model for targets
  * prior           Meaning and syntax of prior specifications

    grid            Output a grid of points  
    extract         Extract items at random from a data file 

  * rand-seed       Specify a random number seed  
    rand-test       Test random number generators

  * quantities      Numeric quantities obtainable from log files

  * xxx-plt         Write quantities from a log file, suitable for plotting
    xxx-hist        Build a histogram for a quantity obtained from a log file

  * series          Analyse stationary time series data


Markov chain Monte Carlo facilities [mc]:

  * mc              Programs and modules supporting Markov chain Monte Carlo 
  * mc-spec         Specify how to do the Markov chain simulation
  * xxx-mc          Run Markov chain simulation

  * mc-quantities   Quantities from log files relating to Monte Carlo 

    mc-temp-sched   Specify temperature schedule for tempering methods
    mc-temp-filter  Copy only iterations at a given temperature

    xxx-grad-test   Test the correctness of the energy gradient computations
    xxx-stepsizes   Display and evaluate stepsizes used for dynamics


Bayesian neural networks [net]:

  * net             Bayesian inference for neural networks using MCMC
  * net-spec        Create a new network, or display existing specifications 

  * net-mc          Do Markov chain simulation to sample networks
  * net-gen         Generate networks from the prior, or with fixed values  

  * net-display     Print network parameters and/or hyperparameters

  * net-quantities  Quantities from log files relating to networks
  * net-plt         Get quantities from a net log file, suitable for plotting
    net-hist        Build histogram for quantity obtained from a net log file

  * net-pred        Make predictions for test cases

    net-eval        Evaluate network functions over a grid  
    net-dvar        Find the variance of a difference in function values

    net-rej         Generate networks from the posterior by rejection sampling


Gaussian process models [gp]:

  * gp              Bayesian modelling using Gaussian processes
  * gp-spec         Specify a Gaussian process model, or display existing spec

  * gp-mc           Use Markov chain to sample Gaussian process hyperparameters
  * gp-gen          Generate GP hyperparameters randomly, or fix them

  * gp-display      Print Gaussian process hyperparameters & other information
  * gp-quantities   Quantities from log files relating to Gaussian processes

  * gp-pred         Make predictions for test cases using Gaussian process
    gp-eval         Evaluate function drawn from a Gaussian process over a grid


Markov chain sampling for a bivariate Gaussian [bvg]:

    bvg             Demo of Markov chain sampling from a bivariate Gaussian
    bvg-spec        Specify a bivariate Gaussian distribution to sample from
    bvg-mc          Do Markov chain simulation for a bivariate Gaussian
    bvg-plt         Get quantities from a bvg log file, suitable to plot


ACKNOWLEDGEMENTS

Inspiration for implementing the Gaussian process methods came from
the work of Carl Rasmussen and Chris Williams.  I also benefitted
from looking at Carl Rasmussen's implementation.

The sampling method for top-level hyperparameters using adaptive
rejection sampling, and the features allowing cpu time to be stored,
displayed, and used to control the number of iterations, are also
based on work by Carl Edward Rasmussen.

Thanks also to David MacKay and Chris Williams for testing the
programs on their machines, and for comments on the documentation.
